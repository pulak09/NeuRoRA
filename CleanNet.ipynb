{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "import h5py\n",
    "import os\n",
    "import hdf5storage\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "datasetR = [] \n",
    "data_path = './'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Test Data'''\n",
    "no_measurements = 100 \n",
    "#filename = data_path+'data/gt_graph_random_large_outliers_real.h5'\n",
    "filename = data_path+'data/gt_graph_random_large_outliers_test.h5'  \n",
    "for item in range(no_measurements): \n",
    "    x = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/x', filename=filename, options=None), dtype=torch.float)\n",
    "    xt = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/xt', filename=filename, options=None), dtype=torch.float)\n",
    "    o = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/o', filename=filename, options=None), dtype=torch.float)\n",
    "    edge_index = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_index', filename=filename, options=None), dtype=torch.long)\n",
    "    edge_attr = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_feature', filename=filename, options=None), dtype=torch.float)\n",
    "    y = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/y', filename=filename, options=None), dtype=torch.float)\n",
    "    datasetR.append(Data(x=x, xt=xt, o=o, y=y, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Train Data'''\n",
    "no_measurements = 1200 \n",
    "filename = data_path+'data/gt_graph_random_large_outliers.h5'  \n",
    "for item in range(no_measurements): \n",
    "    x = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/x', filename=filename, options=None), dtype=torch.float)\n",
    "    xt = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/xt', filename=filename, options=None), dtype=torch.float)\n",
    "    o = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/o', filename=filename, options=None), dtype=torch.float)\n",
    "    edge_index = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_index', filename=filename, options=None), dtype=torch.long)\n",
    "    edge_attr = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/edge_feature', filename=filename, options=None), dtype=torch.float)\n",
    "    y = torch.tensor(hdf5storage.read(path='/data/'+str(item+1)+'/y', filename=filename, options=None), dtype=torch.float)\n",
    "    datasetR.append(Data(x=x, xt=xt, o=o, y=y, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qmul(q, r):\n",
    "    \"\"\"\n",
    "    Multiply quaternion(s) q with quaternion(s) r.\n",
    "    Expects two equally-sized tensors of shape (*, 4), where * denotes any number of dimensions.\n",
    "    Returns q*r as a tensor of shape (*, 4).\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    assert r.shape[-1] == 4\n",
    "\n",
    "    original_shape = q.shape\n",
    "\n",
    "    # Compute outer product\n",
    "    terms = torch.bmm(r.view(-1, 4, 1), q.view(-1, 1, 4))\n",
    "\n",
    "    w = terms[:, 0, 0] - terms[:, 1, 1] - terms[:, 2, 2] - terms[:, 3, 3]\n",
    "    x = terms[:, 0, 1] + terms[:, 1, 0] - terms[:, 2, 3] + terms[:, 3, 2]\n",
    "    y = terms[:, 0, 2] + terms[:, 1, 3] + terms[:, 2, 0] - terms[:, 3, 1]\n",
    "    z = terms[:, 0, 3] - terms[:, 1, 2] + terms[:, 2, 1] + terms[:, 3, 0]\n",
    "    return torch.stack((w, x, y, z), dim=1).view(original_shape)\n",
    "\n",
    "def inv_q(q):\n",
    "    \"\"\"\n",
    "    Inverse quaternion(s) q .\n",
    "    \"\"\"\n",
    "    assert q.shape[-1] == 4\n",
    "    original_shape = q.shape\n",
    "    return torch.stack((q[:, 0], -q[:, 1], -q[:, 2], -q[:, 3]), dim=1).view(original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential as Seq, Linear, ReLU, BatchNorm1d as BN, Dropout\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class EdgeConvRot(MessagePassing):\n",
    "    def __init__(self, in_channels, edge_channels, out_channels):\n",
    "        super(EdgeConvRot, self).__init__(aggr='mean', flow=\"target_to_source\") #  \"Max\" aggregation.\n",
    "        self.mlp0 = Seq(Linear(edge_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "        self.mlp = Seq(Linear(2*in_channels+edge_channels, out_channels),\n",
    "               ReLU(),\n",
    "               Linear(out_channels, out_channels))\n",
    "            \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr): \n",
    "        if x_i.size(1) > 5: \n",
    "            W = torch.cat([torch.cat([x_i, x_j], dim=1), edge_attr], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "            W = self.mlp(W) \n",
    "        else:\n",
    "            W = edge_attr # torch.cat([torch.cat([x_i, x_j], dim=1), edge_attr], dim=1)  # tmp has shape [E, 2 * in_channels]            \n",
    "            W = self.mlp0(W) \n",
    "        return W\n",
    "            \n",
    "    def propagate(self, edge_index, size, x, edge_attr):    \n",
    "        row, col = edge_index\n",
    "        x_i = x[row]\n",
    "        x_j = x[col]\n",
    "        i, j = (0, 1) if self.flow == 'target_to_source' else (1, 0) \n",
    "        edge_out = self.message(x_i, x_j, edge_attr)\n",
    "        out = scatter_(self.aggr, edge_out, edge_index[i], dim_size=size[i])\n",
    "        return out, edge_out \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import scatter_\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "def node_model(x, batch):\n",
    "   # print(batch.shape)\n",
    "    out, inverse_indices = torch.unique_consecutive(batch, return_inverse=True)\n",
    "    quat_vals = x[inverse_indices] \n",
    "    q_ij = qmul(x, inv_q(quat_vals[batch]))  \n",
    "    return q_ij \n",
    "\n",
    "def edge_model(x, edge_index):\n",
    "    row, col = edge_index\n",
    "    q_ij = qmul(x[col], inv_q(x[row]))  \n",
    "    return q_ij \n",
    "\n",
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Linear(channels[i - 1], channels[i]), ReLU())\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class EdgePred(torch.nn.Module):\n",
    "    def __init__(self, in_channels, edge_channels):\n",
    "        super(EdgePred, self).__init__()\n",
    "        self.mlp = Seq(Linear(2*in_channels+edge_channels, 8),\n",
    "                       ReLU(),\n",
    "                       Linear(8, 1)) \n",
    "    def forward(self, xn, edge_index, edge_attr): \n",
    "        row, col = edge_index\n",
    "        xn = torch.cat([xn[row], xn[col], edge_attr], dim=1)\n",
    "        xn = self.mlp(xn) \n",
    "        return torch.sigmoid(xn) \n",
    "    \n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn1, nn2):\n",
    "        super(GlobalSAModule, self).__init__()\n",
    "        self.nn1 = nn1\n",
    "        self.nn2 = nn2\n",
    "\n",
    "    def forward(self, x, batch): \n",
    "        xn = self.nn1(x)\n",
    "      #  xn = F._max_pool1d(xn, x.size(1))\n",
    "       # xn = scatter_('mean', xn, batch)\n",
    "       # xn = xn[batch]  \n",
    "        xn = torch.cat([xn, x], dim=1) \n",
    "     #   print(xn.shape)\n",
    "      #  x = xn.unsqueeze(0).repeat(x.size(0), 1, 1) \n",
    "      #  batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return self.nn2(xn)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_attr(x, edge_index, edge_attr):\n",
    "    row, col = edge_index\n",
    "    x_i = x[row]\n",
    "    x_j = inv_q(x[col])\n",
    "    W=qmul(edge_attr, x_i) \n",
    "    W=qmul(x_j, W) \n",
    "    return W \n",
    "\n",
    "\n",
    "def smooth_l1_loss(input, beta=1. / 5, size_average=False):\n",
    "    \"\"\"\n",
    "    very similar to the smooth_l1_loss from pytorch, but with\n",
    "    the extra beta parameter\n",
    "    \"\"\"\n",
    "    n = torch.abs(input)\n",
    "       \n",
    "    cond = n < beta\n",
    "    loss = torch.where(cond, 0.5 * n ** 2 / beta, n - 0.5 * beta)\n",
    "    if size_average:\n",
    "        return loss.mean()\n",
    "    return loss.sum()\n",
    "\n",
    "def my_smooth_l1_loss(input, beta, alpha=0.05):\n",
    "    \"\"\"\n",
    "    very similar to the smooth_l1_loss from pytorch, but with\n",
    "    the extra beta parameter\n",
    "    \"\"\"\n",
    "    nn = torch.sum(input ** 2, dim=1) \n",
    "    beta = torch.squeeze(beta) \n",
    "    nn = torch.mul(nn, beta) \n",
    "\n",
    "    return nn.sum()\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(Net, self).__init__() \n",
    "        self.no_features = 32   # More features for large dataset \n",
    "        self.conv1 = EdgeConvRot(4, 4, self.no_features) \n",
    "        self.conv2 = EdgeConvRot(self.no_features, self.no_features+4, self.no_features)  \n",
    "        self.conv3 = EdgeConvRot(2*self.no_features, 2*self.no_features, self.no_features) \n",
    "        self.conv4 = EdgeConvRot(2*self.no_features, 2*self.no_features, self.no_features) \n",
    "\n",
    "        self.lin01 = Linear(self.no_features, self.no_features) \n",
    "        self.lin02 = Linear(self.no_features, self.no_features) \n",
    "        self.lin1 = Linear(self.no_features, 4) \n",
    "        self.lin2 = Linear(self.no_features, 1) \n",
    "        \n",
    "        self.m = torch.nn.Sigmoid() \n",
    "    def forward(self, data):\n",
    "        x_org, edge_index, edge_attr, batch, beta = data.x, data.edge_index, data.edge_attr, data.batch, data.o  \n",
    "        \n",
    "        x1, edge_x1 = self.conv1(torch.zeros_like(x_org), edge_index, edge_attr)\n",
    "        x1 = F.relu(x1)\n",
    "        edge_x1 = F.relu(edge_x1)\n",
    "        \n",
    "        x2, edge_x2 = self.conv2(x1, edge_index, torch.cat([edge_attr, edge_x1], dim=1))\n",
    "        x2 = F.relu(x2)\n",
    "        edge_x2 = F.relu(edge_x2)\n",
    "\n",
    "        x3, edge_x3 = self.conv3(torch.cat([x2, x1], dim=1), edge_index, torch.cat([edge_x2, edge_x1], dim=1))\n",
    "        x3 = F.relu(x3)\n",
    "        edge_x3 = F.relu(edge_x3)\n",
    "        \n",
    "        x4, edge_x4 = self.conv4(torch.cat([x3, x2], dim=1), edge_index, torch.cat([edge_x3, edge_x2], dim=1))\n",
    "        edge_x4 = F.relu(edge_x4)\n",
    "        \n",
    "        out01 = self.lin01(edge_x4) \n",
    "        out02 = self.lin02(edge_x4) \n",
    "        \n",
    "      #  print(out.shape) \n",
    "        edge_x = self.lin1(out01) + edge_attr\n",
    "        edge_x = F.normalize(edge_x, p=2, dim=1) \n",
    "        \n",
    "        return self.m(self.lin2(out02)), edge_x, beta   #x, loss1, beta   # node_model(x, batch),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'checkpoint/outliers_detect_new2222.pth' \n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict']) \n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-66039dad99a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mno_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_loader\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mno_testing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mno_testing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "PATH = 'checkpoint/outliers_detect_new222222.pth' \n",
    "import numpy as np \n",
    "no_training = 1200 #round(len(datasetR)*training_exmpl)\n",
    "no_testing = 100 \n",
    "print(no_training) \n",
    "test_loader  = DataLoader(datasetR[:no_testing], batch_size=4, shuffle=True,num_workers=2)\n",
    "train_loader = DataLoader(datasetR[no_testing:], batch_size=4, shuffle=False,num_workers=2)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "model.train()\n",
    "best_loss = 2000 \n",
    "t = time.time() \n",
    "count = 0 \n",
    "val = 14688\n",
    "for epoch in range(250000):\n",
    "    total_loss1 = 0 \n",
    "    total_loss2 = 0 \n",
    "    theta = []\n",
    "    loss = 0 \n",
    "    for idx, data in enumerate(train_loader):\n",
    "        data_gpu = data.to(device)\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "   #     print(data_gpu.y.shape)\n",
    "\n",
    "        out, edge_x, beta = model(data_gpu)\n",
    "    \n",
    "        loss1 = qmul(edge_x, inv_q(edge_model(data_gpu.y, data_gpu.edge_index)))  \n",
    "        loss1 = smooth_l1_loss(loss1[:, 1:])\n",
    "        \n",
    "        loss2 = criterion(out, beta) \n",
    "        loss = 0.1*loss1 + 500*loss2\n",
    "     #   if idx % 2 == 0: \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       # print([idx, loss.item()])\n",
    "       # time.sleep(0.01)\n",
    "        \n",
    "        if epoch % 2 == 0: \n",
    "           # loss1 = qmul(data_gpu.edge_attr, inv_q(edge_model(data_gpu.y, data_gpu.edge_index)))  \n",
    "           # loss1 = smooth_l1_loss(loss1[:, 1:]) \n",
    "            total_loss1 = total_loss1 + loss1.item() \n",
    "            total_loss2 = total_loss2 + loss2.item() \n",
    "            \n",
    "    if epoch % 10 == 0:\n",
    "        for data in test_loader: \n",
    "            data_gpu = data.to(device)\n",
    "            out, edge_x, beta = model(data_gpu)\n",
    "            loss1 = qmul(edge_x, inv_q(edge_model(data_gpu.y, data_gpu.edge_index)))  \n",
    "            loss1 = smooth_l1_loss(loss1[:, 1:])\n",
    "            loss2 = criterion(out, beta) \n",
    "            total_loss1 = total_loss1 + loss1.item() \n",
    "            total_loss2 = total_loss2 + loss2.item()\n",
    "            \n",
    "        count = count + 1\n",
    "    if epoch % 2 == 0: \n",
    "        print([epoch, \"{0:.5f}\".format(total_loss1/no_training), \"{0:.5f}\".format(total_loss2/no_training), \"{0:.3f}\".format(time.time() - t)])\n",
    "        if epoch % 10 == 0:\n",
    "            if val > total_loss1/no_training : \n",
    "                val = total_loss1/no_training \n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    }, PATH) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27bc382994db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m \u001b[0;31m# os.getcwd()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import math \n",
    "import h5py\n",
    "import time \n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "data_path = './' # os.getcwd() \n",
    " \n",
    "PATH = 'checkpoint/outliers_detect_new22222.pth' \n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "model = Net().to(device) \n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "train_loader = DataLoader(datasetR[100:], batch_size=1, shuffle=False)\n",
    "#test_loader = DataLoader(datasetR[:100], batch_size=1, shuffle=False)\n",
    "#test_loader = DataLoader(datasetR, batch_size=1, shuffle=False)\n",
    "#model = best_model \n",
    "#print(best_loss)\n",
    "#pred_rot = []\n",
    "model.eval()\n",
    "total_loss = 0 \n",
    "count = 0 \n",
    "total_time = 0\n",
    "t = time.time() \n",
    "hf = h5py.File(data_path+'data/gt_graph_random_large_outliers_pred_rot.h5', 'w')\n",
    "#hf = h5py.File(data_path+'data/gt_graph_random_large_outliers_test_pred_rot.h5', 'w')\n",
    "theta = [] \n",
    "\n",
    "for data in train_loader: \n",
    "    print(data) \n",
    "    data_gpu = data.to(device)\n",
    "    out, x, beta = model(data_gpu)\n",
    "  #  x = edge_model(data_gpu.xt, data_gpu.edge_index) \n",
    "   # loss = criterion(out, beta)\n",
    "  #  loss = (pred - data_gpu.y).pow(2).sum() \n",
    "  #  total_loss = total_loss + loss.item() \n",
    " #   pred_rot = torch.cat([data.xt, pred, data.y], dim=1).data.cpu().numpy()\n",
    "    hf.create_dataset('/data/'+str(count+1)+'/ot', data=out.data.cpu().numpy())\n",
    "    hf.create_dataset('/data/'+str(count+1)+'/o', data=beta.data.cpu().numpy())\n",
    "  #  hf.create_dataset('/data/'+str(count+1)+'/onode', data=data_gpu.onode.data.cpu().numpy())\n",
    "  #  hf.create_dataset('/data/'+str(count+1)+'/omarker', data=data_gpu.omarker.data.cpu().numpy())\n",
    "    hf.create_dataset('/data/'+str(count+1)+'/refined_qq', data=x.data.cpu().numpy())\n",
    "    hf.create_dataset('/data/'+str(count+1)+'/y', data=data_gpu.y.data.cpu().numpy())\n",
    "    hf.create_dataset('/data/'+str(count+1)+'/xt', data=data_gpu.xt.data.cpu().numpy())\n",
    "    hf.create_dataset('/data/'+str(count+1)+'/edge_index', data=data_gpu.edge_index.data.cpu().numpy())\n",
    "    hf.create_dataset('/data/'+str(count+1)+'/edge_feature', data=data_gpu.edge_attr.data.cpu().numpy())\n",
    "    count = count + 1 \n",
    "   # print([len(pred_rot), (time.time()-t)/len(pred_rot)])\n",
    "#print([total_loss/len(test_loader), (time.time() - t)/(test_loader.batch_size*len(test_loader))])\n",
    "hf.close() \n",
    "   # print([len(pred_rot), (time.time()-t)/len(pred_rot)])\n",
    "print([total_loss/len(train_loader), total_time /(test_loader.batch_size*len(train_loader))]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
